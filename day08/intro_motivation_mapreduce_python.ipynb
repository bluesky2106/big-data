{"nbformat":4,"nbformat_minor":0,"metadata":{"celltoolbar":"Slideshow","kernelspec":{"name":"python3","display_name":"Python 3.9.5 64-bit"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"colab":{"name":"intro_motivation_mapreduce_python.ipynb","provenance":[],"collapsed_sections":["5kZAFCPstl46","xQpZUXBYtl46"]},"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}},"cells":[{"cell_type":"markdown","metadata":{"id":"VUlkWZxttl4n"},"source":["\n","### Overview\n","\n","1. Recap of functional programming in Python\n","2. Python's `map` and `reduce` functions\n","3. Writing parallel code using `map`\n","4. The Map-Reduce programming model\n","\n"]},{"cell_type":"markdown","metadata":{"id":"UnEtaYMetl4o"},"source":["## History\n","\n","- The Map-Reduce programming model was popularised by Google (Dean and Ghemawat 2008).\n","\n","- The first popular open-source implementation was Apache Hadoop, first released in 2011.\n"]},{"cell_type":"markdown","metadata":{"id":"Er-nqtrStl4o"},"source":["## Functional programming\n","\n","Consider the following code:"]},{"cell_type":"code","metadata":{"id":"KItrfbbMtl4p","executionInfo":{"status":"ok","timestamp":1631803720521,"user_tz":-420,"elapsed":17,"user":{"displayName":"Hoài Phương Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09242116126274776227"}}},"source":["def double_everything_in(data):\n","    result = []\n","    for i in data:\n","        result.append(2 * i)\n","    return result\n","\n","def quadruple_everything_in(data):\n","    result = []\n","    for i in data:\n","        result.append(4 * i)\n","    return result"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"wJxh_EdStl4p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631803724882,"user_tz":-420,"elapsed":825,"user":{"displayName":"Hoài Phương Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09242116126274776227"}},"outputId":"e95152cb-498a-4acd-d995-4f3abf2ca2a5"},"source":["double_everything_in([1, 2, 3, 4, 5])"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[2, 4, 6, 8, 10]"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"NSJ9EoXXtl4r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631803731920,"user_tz":-420,"elapsed":416,"user":{"displayName":"Hoài Phương Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09242116126274776227"}},"outputId":"ffccacf3-105b-4480-97c3-dbce440ba2a8"},"source":["quadruple_everything_in([1, 2, 3, 4, 5])"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[4, 8, 12, 16, 20]"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"QWAlQJ_9tl4s"},"source":["### DRY - Fundamental Programming Concept\n","\n","- The above code violates the [\"do not repeat yourself\"](https://en.wikipedia.org/wiki/Don't_repeat_yourself_) principle of good software engineering practice.\n","\n","- How can rewrite the code so that it avoids duplication?"]},{"cell_type":"code","metadata":{"id":"ISBWzZdxtl4t"},"source":["def multiply_by_x_everything_in(x, data):\n","    result = []\n","    for i in data:\n","        result.append(x * i)\n","    return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ktIZ1OZmtl4t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629803833974,"user_tz":-420,"elapsed":429,"user":{"displayName":"David Mai","photoUrl":"","userId":"08130445990978763482"}},"outputId":"c0b1f489-279d-4d39-a1db-5653d2011014"},"source":["multiply_by_x_everything_in(2, [1, 2, 3, 4, 5])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[2, 4, 6, 8, 10]"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"BUb8a_Uatl4t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629803840931,"user_tz":-420,"elapsed":261,"user":{"displayName":"David Mai","photoUrl":"","userId":"08130445990978763482"}},"outputId":"5f03b769-19ec-4f82-c7b2-3488bf821d86"},"source":["multiply_by_x_everything_in(4, [1, 2, 3, 4, 5])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[4, 8, 12, 16, 20]"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"CPY7p5Ebtl4u"},"source":["- Now consider the following code:"]},{"cell_type":"code","metadata":{"id":"DXoqZKbLtl4u"},"source":["def squared(x):\n","    return x*x\n","\n","def double(x):\n","    return x*2\n","\n","def square_everything_in(data):\n","    result = []\n","    for i in data:\n","        result.append(squared(i))\n","    return result\n","\n","def double_everything_in(data):\n","    result = []\n","    for i in data:\n","        result.append(double(i))\n","    return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V8or_BFdtl4v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629803864537,"user_tz":-420,"elapsed":8,"user":{"displayName":"David Mai","photoUrl":"","userId":"08130445990978763482"}},"outputId":"2e1b48a7-8183-45c3-f839-e1329dc6caf0"},"source":["square_everything_in([1, 2, 3, 4, 5])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 4, 9, 16, 25]"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"mpCMj4vPtl4v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629803870431,"user_tz":-420,"elapsed":373,"user":{"displayName":"David Mai","photoUrl":"","userId":"08130445990978763482"}},"outputId":"7ec6014a-d8ce-4468-924f-fe1e039e2333"},"source":["double_everything_in([1, 2, 3, 4, 5])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[2, 4, 6, 8, 10]"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"lojs3rlCtl4v"},"source":["### DRY - Fundamental Programming Concept\n","- The above code violates the [\"do not repeat yourself\"](https://en.wikipedia.org/wiki/Don't_repeat_yourself_) principle of good software engineering practice.\n","\n","- How can rewrite the code so that it avoids duplication?"]},{"cell_type":"markdown","metadata":{"id":"VEaY6aMwtl4w"},"source":["### Passing Functions as Values\n","- Functions can be passed to other functions as values.\n","-\n"]},{"cell_type":"code","metadata":{"id":"607XT-K4tl4w"},"source":["def apply_f_to_everything_in(f, data):\n","    result = []\n","    for x in data:\n","        result.append(f(x))\n","    return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SyaNOZyBtl4w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627953513408,"user_tz":-420,"elapsed":61,"user":{"displayName":"David Mai","photoUrl":"","userId":"08130445990978763482"}},"outputId":"3a940165-fb84-46b4-a6bc-417d3f9dd6b8"},"source":["apply_f_to_everything_in(squared, [1, 2, 3, 4, 5])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 4, 9, 16, 25]"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"IxvB3bnttl4w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629803982984,"user_tz":-420,"elapsed":330,"user":{"displayName":"David Mai","photoUrl":"","userId":"08130445990978763482"}},"outputId":"c4bf60f2-9a77-42c2-ecf1-56bdafb9193c"},"source":["apply_f_to_everything_in(double, [1, 2, 3, 4, 5])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[2, 4, 6, 8, 10]"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"erfHheistl4x"},"source":["### Lambda expressions\n","\n","- We can use anonymous functions to save having to define a function each time we want to use map."]},{"cell_type":"code","metadata":{"id":"1e8mkM2Ctl4x","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629804000830,"user_tz":-420,"elapsed":279,"user":{"displayName":"David Mai","photoUrl":"","userId":"08130445990978763482"}},"outputId":"ac8a740c-9b26-45ec-b724-9f523168592f"},"source":["apply_f_to_everything_in(lambda x: x*x, [1, 2, 3, 4, 5])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 4, 9, 16, 25]"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"Ov5HqJHetl4x"},"source":["# Python's `map` function\n","\n","- Python has a built-in function `map` which is much faster than our version.\n","\n"]},{"cell_type":"code","metadata":{"id":"Xthp90Nvtl4x","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631849891451,"user_tz":-420,"elapsed":361,"user":{"displayName":"Hoài Phương Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09242116126274776227"}},"outputId":"1163a615-138e-425a-f058-d60879a0b2b7"},"source":["map(lambda x: x*x, [1, 2, 3, 4, 5])"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<map at 0x7efe76e8d390>"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"A5FhLeVWtl4y"},"source":["## Implementing reduce\n","\n","- The `reduce` function is an example of a [fold](https://en.wikipedia.org/wiki/Fold_%28higher-order_function%29).\n","\n","- There are different ways we can fold data.\n","\n","- The following implements a *left* fold.\n"]},{"cell_type":"code","metadata":{"id":"2Rr0gPj_tl4y"},"source":["def foldl(f, data, z):\n","    if (len(data) == 0):\n","        print (z)\n","        return z\n","    else:\n","        head = data[0]\n","        tail = data[1:]\n","        print (\"Folding\", head, \"with\", tail, \"using\", z)\n","        partial_result = f(z, data[0])\n","        print (\"Partial result is\", partial_result)\n","        return foldl(f, tail, partial_result)  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BffOLSjctl4y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629804168978,"user_tz":-420,"elapsed":348,"user":{"displayName":"David Mai","photoUrl":"","userId":"08130445990978763482"}},"outputId":"20d3eb8a-dd69-4ebf-c190-55c0f328d682"},"source":["def add(x, y):\n","    return x + y\n","\n","foldl(add, [3, 3, 3, 3, 3], 0)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Folding 3 with [3, 3, 3, 3] using 0\n","Partial result is 3\n","Folding 3 with [3, 3, 3] using 3\n","Partial result is 6\n","Folding 3 with [3, 3] using 6\n","Partial result is 9\n","Folding 3 with [3] using 9\n","Partial result is 12\n","Folding 3 with [] using 12\n","Partial result is 15\n","15\n"]},{"output_type":"execute_result","data":{"text/plain":["15"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"X2c8pZeWtl4y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629804261674,"user_tz":-420,"elapsed":246,"user":{"displayName":"David Mai","photoUrl":"","userId":"08130445990978763482"}},"outputId":"03ce929d-ab6e-48d2-a33e-6be6623afc22"},"source":["foldl(lambda x, y: x + y, [1, 2, 3, 4, 5], 0)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Folding 1 with [2, 3, 4, 5] using 0\n","Partial result is 1\n","Folding 2 with [3, 4, 5] using 1\n","Partial result is 3\n","Folding 3 with [4, 5] using 3\n","Partial result is 6\n","Folding 4 with [5] using 6\n","Partial result is 10\n","Folding 5 with [] using 10\n","Partial result is 15\n","15\n"]},{"output_type":"execute_result","data":{"text/plain":["15"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"wdMy-s1gtl4z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629804269552,"user_tz":-420,"elapsed":247,"user":{"displayName":"David Mai","photoUrl":"","userId":"08130445990978763482"}},"outputId":"275b426c-8175-4564-9d64-a70405b66eef"},"source":["foldl(lambda x, y: x - y, [1, 2, 3, 4, 5], 0)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Folding 1 with [2, 3, 4, 5] using 0\n","Partial result is -1\n","Folding 2 with [3, 4, 5] using -1\n","Partial result is -3\n","Folding 3 with [4, 5] using -3\n","Partial result is -6\n","Folding 4 with [5] using -6\n","Partial result is -10\n","Folding 5 with [] using -10\n","Partial result is -15\n","-15\n"]},{"output_type":"execute_result","data":{"text/plain":["-15"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"9pEE26o3tl4z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629804295859,"user_tz":-420,"elapsed":245,"user":{"displayName":"David Mai","photoUrl":"","userId":"08130445990978763482"}},"outputId":"74527ffa-44d2-4965-c954-a09ffa28b13f"},"source":["(((((0 - 1) - 2) - 3) - 4) - 5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["-15"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"P9RGnLIctl4z"},"source":["- Subtraction is neither [commutative](https://en.wikipedia.org/wiki/Commutative_property) nor [associative](https://en.wikipedia.org/wiki/Associative_property), so the order in which apply the fold matters:"]},{"cell_type":"code","metadata":{"id":"oIfG7Zxntl4z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629804313300,"user_tz":-420,"elapsed":277,"user":{"displayName":"David Mai","photoUrl":"","userId":"08130445990978763482"}},"outputId":"79c7dca5-ac46-4d77-ef07-edd505ad7ddf"},"source":["(1 - (2 - (3 - (4 - (5 - 0)))))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"aMtG-dSZtl4z"},"source":["def foldr(f, data, z):\n","    if (len(data) == 0):\n","        return z\n","    else:\n","        return f(data[0], foldr(f, data[1:], z))                "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-_XOcMintl40","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629804331600,"user_tz":-420,"elapsed":302,"user":{"displayName":"David Mai","photoUrl":"","userId":"08130445990978763482"}},"outputId":"ee3b97c2-12ef-4f64-e7c7-72399a295af4"},"source":["foldl(lambda x, y: x - y,  [1, 2, 3, 4, 5], 0)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Folding 1 with [2, 3, 4, 5] using 0\n","Partial result is -1\n","Folding 2 with [3, 4, 5] using -1\n","Partial result is -3\n","Folding 3 with [4, 5] using -3\n","Partial result is -6\n","Folding 4 with [5] using -6\n","Partial result is -10\n","Folding 5 with [] using -10\n","Partial result is -15\n","-15\n"]},{"output_type":"execute_result","data":{"text/plain":["-15"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"Udv4ZFmXtl40","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629804349227,"user_tz":-420,"elapsed":282,"user":{"displayName":"David Mai","photoUrl":"","userId":"08130445990978763482"}},"outputId":"68f44102-7c24-480a-b8e7-06e454ec7f0a"},"source":["foldr(lambda x, y: x - y, [1, 2, 3, 4, 5], 0)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"6qkagLEatl40"},"source":["## Python's `reduce` function.\n","\n","- Python's built-in `reduce` function is a *left* fold."]},{"cell_type":"code","metadata":{"id":"z2wqZLH8tl40","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631850134586,"user_tz":-420,"elapsed":355,"user":{"displayName":"Hoài Phương Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09242116126274776227"}},"outputId":"1c4a0701-7d40-41f2-d341-3e5f05a99668"},"source":["from functools import reduce\n","reduce(lambda x, y: x + y, [1, 2, 3, 4, 5])"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["15"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"Ydxb9yQYtl41","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629804403655,"user_tz":-420,"elapsed":245,"user":{"displayName":"David Mai","photoUrl":"","userId":"08130445990978763482"}},"outputId":"8d29b717-d294-41ae-ffbf-72e8d0982342"},"source":["reduce(lambda x, y: x - y, [1, 2, 3, 4, 5], 0)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["-15"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"EChnfJgQtl41","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629804408360,"user_tz":-420,"elapsed":347,"user":{"displayName":"David Mai","photoUrl":"","userId":"08130445990978763482"}},"outputId":"5adcdfd2-6966-4524-daf9-be00d3e316d5"},"source":["foldl(lambda x, y: x - y, [1, 2, 3, 4, 5], 0)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Folding 1 with [2, 3, 4, 5] using 0\n","Partial result is -1\n","Folding 2 with [3, 4, 5] using -1\n","Partial result is -3\n","Folding 3 with [4, 5] using -3\n","Partial result is -6\n","Folding 4 with [5] using -6\n","Partial result is -10\n","Folding 5 with [] using -10\n","Partial result is -15\n","-15\n"]},{"output_type":"execute_result","data":{"text/plain":["-15"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"HfxFaiQgtl41"},"source":["# Functional programming and parallelism\n","\n","- Functional programming lends itself to [parallel programming](https://computing.llnl.gov/tutorials/parallel_comp/#Models).\n","\n","- The `map` function can easily be parallelised through [data-level parallelism](https://en.wikipedia.org/wiki/Data_parallelism),\n","    - provided that the function we supply as an argument is *free from* [side-effects](https://en.wikipedia.org/wiki/Side_effect_%28computer_science%29)\n","        - (which is why we avoid working with mutable data).\n","\n","- We can see this by rewriting it so:\n"]},{"cell_type":"code","metadata":{"id":"0fmyo_mDtl41"},"source":["def perform_computation(f, result, data, i):\n","    print (\"Computing the \", i, \"th result...\")\n","    # This could be scheduled on a different CPU\n","    result[i] = f(data[i])\n","\n","def my_map(f, data):\n","    result = [None] * len(data)\n","    for i in range(len(data)):\n","        perform_computation(f, result, data, i)\n","    # Wait for other CPUs to finish, and then..\n","    return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ONvlsTx7tl41","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629804493528,"user_tz":-420,"elapsed":271,"user":{"displayName":"David Mai","photoUrl":"","userId":"08130445990978763482"}},"outputId":"eb912aa7-ae05-4381-f559-d4cdffd31406"},"source":["my_map(lambda x: x * x, [1, 2, 3, 4, 5])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Computing the  0 th result...\n","Computing the  1 th result...\n","Computing the  2 th result...\n","Computing the  3 th result...\n","Computing the  4 th result...\n"]},{"output_type":"execute_result","data":{"text/plain":["[1, 4, 9, 16, 25]"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"jit3MJu2tl42"},"source":["## A multi-threaded `map` function"]},{"cell_type":"code","metadata":{"id":"FsT8BJrrtl42","executionInfo":{"status":"ok","timestamp":1631849161815,"user_tz":-420,"elapsed":365,"user":{"displayName":"Hoài Phương Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09242116126274776227"}}},"source":["from threading import Thread\n","\n","def schedule_computation_threaded(f, result, data, threads, i):    \n","    # Each function evaluation is scheduled on a different core.\n","    def my_job(): \n","        print (\"Processing data:\", data[i], \"... \")\n","        result[i] = f(data[i])\n","        print (\"Finished job #\", i)    \n","        print (\"Result was\", result[i])       \n","    threads[i] = Thread(target=my_job)\n","    \n","def my_map_multithreaded(f, data):\n","    n = len(data)\n","    result = [None] * n\n","    threads = [None] * n\n","    print (\"Scheduling jobs.. \")\n","    for i in range(n):\n","        schedule_computation_threaded(f, result, data, threads, i)\n","    print (\"Starting jobs.. \")\n","    for i in range(n):\n","        threads[i].start()\n","    print (\"Waiting for jobs to finish.. \")\n","    for i in range(n):\n","        threads[i].join()\n","    print (\"All done.\")\n","    return result"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"gjcWZUAftl42","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631849164060,"user_tz":-420,"elapsed":364,"user":{"displayName":"Hoài Phương Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09242116126274776227"}},"outputId":"2ea9b60f-05fe-4ab1-88da-4b226ecedff8"},"source":["my_map_multithreaded(lambda x: x*x, [1, 2, 3, 4, 5])"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Scheduling jobs.. \n","Starting jobs.. \n","Processing data:Processing data: 2Processing data: 3 ... \n","Finished job # 1\n","Result was 4\n","  Processing data:1Processing data:...  4 ... \n","Finished job #Waiting for jobs to finish.. \n","\n","Finished job # 2\n","  ... \n","Finished job # 0\n","Result was Result was 9\n","3\n","Result was 16\n","1\n"," 5 ... \n","Finished job # 4\n","Result was 25\n","All done.\n"]},{"output_type":"execute_result","data":{"text/plain":["[1, 4, 9, 16, 25]"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"yEV4ea1Etl42","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629804696701,"user_tz":-420,"elapsed":10106,"user":{"displayName":"David Mai","photoUrl":"","userId":"08130445990978763482"}},"outputId":"5827fd16-77f4-450a-b91b-752d4795f1f4"},"source":["from numpy.random import uniform\n","from time import sleep\n","\n","def a_function_which_takes_a_long_time(x):\n","    sleep(uniform(2, 10))  # Simulate some long computation\n","    return x*x\n","\n","my_map_multithreaded(a_function_which_takes_a_long_time, [1, 2, 3, 4, 5])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Scheduling jobs.. \n","Starting jobs.. \n","Processing data: Processing data: 1 ... \n","2Processing data: ...  3 ... \n","\n","Processing data: 4 ... \n","Processing data: 5 ... \n","Waiting for jobs to finish.. \n","Finished job # 2\n","Result was 9\n","Finished job # 4\n","Result was 25\n","Finished job # 0\n","Result was 1\n","Finished job # 3\n","Result was 16\n","Finished job # 1\n","Result was 4\n","All done.\n"]},{"output_type":"execute_result","data":{"text/plain":["[1, 4, 9, 16, 25]"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"gx2Itg6Ptl42"},"source":["## Map Reduce\n","\n","- Map Reduce is a _programming model_ for scalable parallel processing.\n","- Scalable here means that it can work on big data with very large compute clusters.\n","- There are many implementations: e.g. Apache Hadoop and Apache Spark.\n","- We can use Map-Reduce with any programming language:\n","    - Hadoop is written in Java\n","    - Spark is written in Scala, but has a Python interface.\n","- *Functional programming* languages such as Python or Scala fit very well with the Map Reduce model:\n","    - However, we don't *have* to use functional programming."]},{"cell_type":"markdown","metadata":{"id":"mFvetFDVD6e6"},"source":["![MapReduce](https://github.com/pnavaro/big-data/blob/master/notebooks/images/mapreduce.jpg?raw=1)"]},{"cell_type":"markdown","metadata":{"id":"WS28lTmatl42"},"source":["- A MapReduce implementation will take care of the low-level functionality so that you don't have to worry about:\n","    - load balancing\n","    - network I/O\n","    - network and disk transfer optimisation\n","    - handling of machine failures\n","    - serialization of data\n","    - etc..\n","- The model is designed to move the processing to where the data resides."]},{"cell_type":"markdown","metadata":{"id":"UIrEYEnVtl43"},"source":["## Typical steps in a Map Reduce Computation\n","\n","1. ETL a big data set.\n","2. _Map_ operation: extract something you care about from each row\n","3. \"Shuffle and Sort\": task/node allocation\n","4. _Reduce_ operation: aggregate, summarise, filter or transform\n","5. Write the results."]},{"cell_type":"markdown","metadata":{"id":"etM5ZAYYtl43"},"source":["## Callbacks for Map Reduce\n","\n","- The data set, and the state of each stage of the computation, is represented as a set of key-value pairs.\n","\n","- The programmer provides a map function:\n","\n","$\\operatorname{map}(k, v) \\rightarrow \\; \\left< k', v' \\right>*$  \n","\n","- and a reduce function:\n","\n","$\\operatorname{reduce}(k', \\left< k', v'\\right> *) \\rightarrow \\; \\left< k', v''\n","\\right> *$\n","\n","- The $*$ refers to a *collection* of values.\n","\n","- These collections are *not* ordered."]},{"cell_type":"markdown","metadata":{"id":"ec-rrLrHDe2l"},"source":["This part is to code in Python language a wordcount application using map-reduce process. A java version is well explained on [this page](https://www.dezyre.com/hadoop-tutorial/hadoop-mapreduce-wordcount-tutorial)\n","\n","![domain decomposition](https://github.com/pnavaro/big-data/blob/master/notebooks/images/domain_decomp.png?raw=1)\n","\n","credits: https://computing.llnl.gov/tutorials/parallel_comp"]},{"cell_type":"markdown","metadata":{"id":"0FAXBh-Wtl43"},"source":["## Word Count Example\n","\n","- In this simple example, the input is a set of URLs, each record is a document.\n","\n","- Problem: compute how many times each word has occurred across data set."]},{"cell_type":"markdown","metadata":{"id":"PRL0h0Lhtl43"},"source":["## Word Count: Map \n","\n","\n","- The input to $\\operatorname{map}$ is a mapping:\n","\n","- Key: URL\n","- Value: Contents of document"]},{"cell_type":"markdown","metadata":{"id":"tbJefeRntl43"},"source":["$\\left< document1, to \\; be \\; or \\; not \\; to \\; be \\right>$  \n","    \n","\n","- In this example, our $\\operatorname{map}$ function will process a given URL, and produces a mapping:"]},{"cell_type":"markdown","metadata":{"id":"IMtA3pz8tl43"},"source":["- Key: word\n","- Value: 1\n","\n","- So our original data-set will be transformed to:\n","  \n","  $\\left< to, 1 \\right>$\n","  $\\left< be, 1 \\right>$\n","  $\\left< or, 1 \\right>$\n","  $\\left< not, 1 \\right>$\n","  $\\left< to, 1 \\right>$\n","  $\\left< be, 1 \\right>$"]},{"cell_type":"markdown","metadata":{"id":"O2qbbsrGtl43"},"source":["## Word Count: Reduce\n","\n","\n","- The reduce operation groups values according to their key, and then performs areduce on each key.\n","\n","- The collections are partitioned across different storage units, therefore.\n","\n","- Map-Reduce will fold the data in such a way that it minimises data-copying across the cluster.\n","\n","- Data in different partitions are reduced separately in parallel.\n","\n","- The final result is a reduce of the reduced data in each partition.\n","\n","- Therefore it is very important that our operator *is both commutative and associative*.\n","\n","- In our case the function is the `+` operator\n","\n","  $\\left< be, 2 \\right>$  \n","  $\\left< not, 1 \\right>$  \n","  $\\left< or, 1 \\right>$  \n","  $\\left< to, 2 \\right>$  \n","  "]},{"cell_type":"markdown","metadata":{"id":"DWHFF8sEtl44"},"source":["## Map and Reduce compared with Python\n","\n","- Notice that these functions are formulated differently from the standard Python functions of the same name.\n","\n","- The `reduce` function works with key-value *pairs*.\n","\n","- It would be more apt to call it something like `reduceByKey`.\n"]},{"cell_type":"markdown","metadata":{"id":"fkZt8lI4tl44"},"source":["## MiniMapReduce\n","\n","- To illustrate how the Map-Reduce programming model works, we can implement our own Map-Reduce framework in Python.\n","\n","- This *illustrates* how a problem can be written in terms of `map` and `reduce` operations.\n","\n","- Note that these are illustrative functions; this is *not* how Hadoop or Apache Spark actually implement them."]},{"cell_type":"code","metadata":{"id":"pCXHugVwtl44","executionInfo":{"status":"ok","timestamp":1631850059560,"user_tz":-420,"elapsed":425,"user":{"displayName":"Hoài Phương Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09242116126274776227"}}},"source":["##########################################################\n","#\n","#   MiniMapReduce\n","#\n","# A non-parallel, non-scalable Map-Reduce implementation\n","##########################################################\n","\n","def groupByKey(data):\n","    result = dict()\n","    for key, value in data:\n","        if key in result:\n","            result[key].append(value)\n","        else:\n","            result[key] = [value]\n","    return result\n","        \n","def reduceByKey(f, data):\n","    key_values = groupByKey(data)\n","    return map(lambda key: \n","                   (key, reduce(f, key_values[key])), \n","                       key_values)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EC0QrL7dtl44"},"source":["## Word-count using MiniMapReduce\n"]},{"cell_type":"code","metadata":{"id":"z3LFtr7etl44","executionInfo":{"status":"ok","timestamp":1631850142577,"user_tz":-420,"elapsed":351,"user":{"displayName":"Hoài Phương Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09242116126274776227"}}},"source":["data = map(lambda x: (x, 1), \"to be or not to be\".split())\n","# print(list(data))"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"KPGfpO66tl45","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631850094875,"user_tz":-420,"elapsed":591,"user":{"displayName":"Hoài Phương Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09242116126274776227"}},"outputId":"a4c079e5-e2ac-4184-8b25-cf4b369177eb"},"source":["groupByKey(data)"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'be': [1, 1], 'not': [1], 'or': [1], 'to': [1, 1]}"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"Z2w3iWuUtl45","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631850144996,"user_tz":-420,"elapsed":5,"user":{"displayName":"Hoài Phương Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09242116126274776227"}},"outputId":"de87b854-f16a-4841-9ca1-625e092b9dbc"},"source":["res = reduceByKey(lambda x, y: x + y, data)\n","print(list(res))"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["[('to', 2), ('be', 2), ('or', 1), ('not', 1)]\n"]}]},{"cell_type":"markdown","metadata":{"id":"yPginmvJtl45"},"source":["## Parallelising MiniMapReduce\n","\n","- We can easily turn our Map-Reduce implementation into a parallel, multi-threaded framework\n","by using the `my_map_multithreaded` function we defined earlier.\n","\n","- This will allow us to perform map-reduce computations that exploit parallel processing using *multiple* cores on a *single* computer."]},{"cell_type":"code","metadata":{"id":"iBbyFVlOtl45"},"source":["def reduceByKey_multithreaded(f, data):\n","    key_values = groupByKey(data)\n","    return my_map_multithreaded(\n","        lambda key: (key, reduce(f, key_values[key])), key_values.keys())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ia87FJXAtl45","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627953520271,"user_tz":-420,"elapsed":45,"user":{"displayName":"David Mai","photoUrl":"","userId":"08130445990978763482"}},"outputId":"df97e4c2-2ed5-4143-ef3d-f1c47a0ad6ef"},"source":["reduceByKey_multithreaded(lambda x, y: x + y, data)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Scheduling jobs.. \n","Starting jobs.. \n","Waiting for jobs to finish.. \n","All done.\n"]},{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"markdown","metadata":{"id":"bIKtbfKvtl46"},"source":["## Parallelising the reduce step\n","\n","- Provided that our operator is both associative and commutative we can\n","also parallelise the reduce operation.\n","\n","- We partition the data into approximately equal subsets.\n","\n","- We then reduce each subset independently on a separate core.\n","\n","- The results can be combined in a final reduce step."]},{"cell_type":"markdown","metadata":{"id":"5kZAFCPstl46"},"source":["### Partitioning the data"]},{"cell_type":"code","metadata":{"id":"M9bWNqmxtl46","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627953520272,"user_tz":-420,"elapsed":43,"user":{"displayName":"David Mai","photoUrl":"","userId":"08130445990978763482"}},"outputId":"1b73abd1-5f1d-44a8-ecdd-6af01fd8021b"},"source":["def split_data(data, split_points):\n","    partitions = []\n","    n = 0\n","    for i in split_points:\n","        partitions.append(data[n:i])\n","        n = i\n","    partitions.append(data[n:])\n","    return partitions\n","\n","data = ['a', 'b', 'c', 'd', 'e', 'f', 'g']\n","partitioned_data = split_data(data, [3])\n","partitioned_data"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['a', 'b', 'c'], ['d', 'e', 'f', 'g']]"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"markdown","metadata":{"id":"xQpZUXBYtl46"},"source":["### Reducing across partitions in parallel"]},{"cell_type":"code","metadata":{"id":"IU5D3SC_tl46","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1627953520273,"user_tz":-420,"elapsed":40,"user":{"displayName":"David Mai","photoUrl":"","userId":"08130445990978763482"}},"outputId":"b71af431-9650-4405-cad4-8422b7dfcdb3"},"source":["from threading import Thread\n","\n","def parallel_reduce(f, partitions):\n","\n","    n = len(partitions)\n","    results = [None] * n\n","    threads = [None] * n\n","    \n","    def job(i):\n","        results[i] = reduce(f, partitions[i])\n","\n","    for i in range(n):\n","        threads[i] = Thread(target = lambda: job(i))\n","        threads[i].start()\n","    \n","    for i in range(n):\n","        threads[i].join()\n","    \n","    return reduce(f, results)\n","\n","parallel_reduce(lambda x, y: x + y, partitioned_data)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'abcdefg'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"w2wM_1F2tl46"},"source":["## Map-Reduce on a cluster of computers\n","\n","- The code we have written so far will *not* allow us to exploit parallelism from multiple computers in a [cluster](https://en.wikipedia.org/wiki/Computer_cluster).\n","\n","- Developing such a framework would be a very large software engineering project.\n","\n","- There are existing frameworks we can use:\n","    - [Apache Hadoop](https://hadoop.apache.org/)\n","    - [Apache Spark](https://spark.apache.org/)\n","    \n","- In our program, we will mostly focus on Apache Spark."]},{"cell_type":"code","metadata":{"id":"UF-FeXiiC_eM"},"source":[""],"execution_count":null,"outputs":[]}]}